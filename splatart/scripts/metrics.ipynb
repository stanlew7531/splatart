{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import json\n",
    "\n",
    "# Read .ply file\n",
    "transforms_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_0/dataparser_transforms.json\"\n",
    "splatcloud_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/exports/splat/splat.ply\"\n",
    "\n",
    "splatcloud = o3d.io.read_point_cloud(splatcloud_path)\n",
    "# Get and invert transforms\n",
    "transforms = json.load(open(transforms_path, 'r'))\n",
    "inv_scale = 1.0 / transforms['scale']\n",
    "\n",
    "linear = np.array(transforms['transform'])[0:3, 0:3]\n",
    "T = np.array(transforms['transform'])[0:3, 3]\n",
    "inv = np.linalg.inv(linear)\n",
    "\n",
    "inv_hom = np.eye(4)\n",
    "inv_hom[0:3, 0:3] = inv\n",
    "inv_hom[0:3, 3] = -inv @ T\n",
    "\n",
    "# apply transforms\n",
    "# splatcloud.transform(inv_hom)\n",
    "# splatcloud.scale(inv_scale, center=(0, 0, 0))\n",
    "\n",
    "# correct for convention difference\n",
    "# R = o3d.geometry.get_rotation_matrix_from_xyz((0, 0, np.pi/2))\n",
    "# splatcloud.rotate(R, center=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get canonical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['original-3', 'original-2', 'original-5', 'original-31', 'original-32']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read .ply file\n",
    "paris_to_sapien = {\n",
    "    'blade': '103706',\n",
    "    'laptop': '10211',\n",
    "    'foldchair': '102255',\n",
    "    'oven': '101917',\n",
    "    'fridge': '10905',\n",
    "    'scissor': '11100',\n",
    "    'stapler': '103111',\n",
    "    'USB': '100109',\n",
    "    'washer': '103776',\n",
    "    'storage': '45135'\n",
    "}\n",
    "\n",
    "name = 'blade'\n",
    "sapien_dir = '/home/vishalchandra/Desktop/sapien_dataset/' + paris_to_sapien[name] + '/'\n",
    "description = json.load(open(sapien_dir + 'result.json'))[0]\n",
    "parts = description['children']\n",
    "\n",
    "parts_files = [part['objs'] for part in parts]\n",
    "parts_files[0][:5] #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TriangleMesh with 290 points and 248 triangles.,\n",
       " TriangleMesh with 38 points and 30 triangles.,\n",
       " TriangleMesh with 80 points and 80 triangles.,\n",
       " TriangleMesh with 96 points and 96 triangles.,\n",
       " TriangleMesh with 72 points and 70 triangles.]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonical_part_objs = [\n",
    "    [o3d.io.read_triangle_mesh(sapien_dir + 'textured_objs/' + obj + '.obj') for obj in part]\n",
    "    for part in parts_files\n",
    "]\n",
    "canonical_part_objs[0][:5] #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all triangle meshes to a single mesh but keep them separate\n",
    "canonical_parts = []\n",
    "for part in canonical_part_objs:\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    for obj in part:\n",
    "        mesh += obj\n",
    "    canonical_parts.append(mesh)\n",
    "\n",
    "# correct for convention difference between sapien and reconstruction\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((np.pi/2, -np.pi/2, 0))\n",
    "for part in canonical_parts:\n",
    "    part.rotate(R, center=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Reconstructed Parts from Gauss Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Don't need to interact with pipelines\n",
    "# from splatart.managers.SplatManager import SplatManager, load_model\n",
    "# to be cmd line args\n",
    "# model_dirs = [\n",
    "#     '/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_0',\n",
    "#     '/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_1'\n",
    "# ]\n",
    "# num_classes = 4\n",
    "# ns_base_path = '/home/vishalchandra/Desktop/nerfstudio_dev/'\n",
    "\n",
    "# trainer_config, pipeline, ckpt_path = load_model(model_dirs[0], 'config.yml', ns_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "manager_paths = [\n",
    "    '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/splat_manager_0.pth',\n",
    "    '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/splat_manager_1.pth'\n",
    "]\n",
    "\n",
    "managers = [torch.load(manager_path) for manager_path in manager_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyElement, PlyData\n",
    "import numpy as np\n",
    "\n",
    "# adapted from https://github.com/nerfstudio-project/gsplat/issues/234#issuecomment-2197277211\n",
    "def part_to_ply(part, part_num):\n",
    "\n",
    "    xyz = part[\"means\"].detach().cpu().numpy()\n",
    "    normals = np.zeros_like(xyz)\n",
    "    f_dc = part[\"features_dc\"].detach().contiguous().cpu().numpy()\n",
    "    f_rest = part[\"features_rest\"].transpose(1, 2).flatten(start_dim=1).detach().contiguous().cpu().numpy()\n",
    "    opacities = part[\"opacities\"].detach().cpu().numpy()\n",
    "    scale = part[\"scales\"].detach().cpu().numpy()\n",
    "    rotation = part[\"quats\"].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    l = ['x', 'y', 'z', 'nx', 'ny', 'nz']\n",
    "    # All channels except the 3 DC\n",
    "    for i in range(part.features_dc.shape[1]):\n",
    "        l.append('f_dc_{}'.format(i))\n",
    "    for i in range(part.features_rest.shape[1]*part.features_rest.shape[2]):\n",
    "        l.append('f_rest_{}'.format(i))\n",
    "    l.append('opacity')\n",
    "    for i in range(part.scales.shape[1]):\n",
    "        l.append('scale_{}'.format(i))\n",
    "    for i in range(part.quats.shape[1]):\n",
    "        l.append('rot_{}'.format(i))\n",
    "\n",
    "    dtype_full = [(attribute, 'f4') for attribute in l]\n",
    "\n",
    "    elements = np.empty(xyz.shape[0], dtype=dtype_full)\n",
    "    attributes = np.concatenate((xyz, normals, f_dc, f_rest, opacities, scale, rotation), axis=1)\n",
    "    elements[:] = list(map(tuple, attributes))\n",
    "    el = PlyElement.describe(elements, 'vertex')\n",
    "    PlyData([el]).write('part{}.ply'.format(part_num))\n",
    "\n",
    "\n",
    "for i in range(2, managers[0].num_parts):\n",
    "    part = managers[0].parts_gauss_params[i]\n",
    "    part_to_ply(part, i-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare recon and canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_corresp = {\n",
    "    0: 1,\n",
    "    1: 0\n",
    "}\n",
    "\n",
    "recon_part_clouds = [\n",
    "    o3d.io.read_point_cloud('part{}.ply'.format(i)) for i in range(2)\n",
    "]\n",
    "\n",
    "# apply transforms\n",
    "for part_cloud in recon_part_clouds:\n",
    "    part_cloud.transform(inv_hom)\n",
    "    part_cloud.scale(inv_scale, center=(0, 0, 0))\n",
    "\n",
    "canonical_part_clouds = [\n",
    "    canonical_parts[canonical_corresp[i]].sample_points_uniformly(len(recon_part_clouds[i].points))\n",
    "    for i in range(2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=1.042831e-01, inlier_rmse=1.186440e-02, and correspondence_set size of 56\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99998343  0.00512667  0.00261757  0.00511719]\n",
      " [-0.00503273  0.99938458 -0.03471501  0.00425996]\n",
      " [-0.00279394  0.03470126  0.99939382 -0.00472462]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# register moving parts\n",
    "# here, we know it's part 1\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    recon_part_clouds[1], canonical_part_clouds[1], 0.02, np.eye(4),\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    ")\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_745210/331524817.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  recon_T = torch.tensor(recon_cloud.points).float().unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(0.0007), tensor(0.0351)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "part_chamfers = []\n",
    "movable = [1]\n",
    "for i in range(2):\n",
    "\n",
    "    recon_cloud = recon_part_clouds[i]\n",
    "    canonical_cloud = canonical_part_clouds[i]\n",
    "\n",
    "    if i in movable:\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            recon_part_clouds[1], canonical_part_clouds[1], 0.02, np.eye(4),\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "        )\n",
    "        recon_cloud.transform(reg_p2p.transformation)\n",
    "        \n",
    "    recon_T = torch.tensor(recon_cloud.points).float().unsqueeze(0)\n",
    "    canonical_T = torch.tensor(canonical_cloud.points).float().unsqueeze(0)\n",
    "\n",
    "    a, _ = chamfer_distance(recon_T, canonical_T)\n",
    "    b, _ = chamfer_distance(canonical_T, recon_T)\n",
    "    part_chamfers.append((a + b)/2)\n",
    "\n",
    "part_chamfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0007)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splatcloud_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/exports/splat/splat.ply\"\n",
    "gtmesh_path = \"/home/vishalchandra/Desktop/splatart_data/narf_sapien_data/v5/blade/0/blade_0.ply\"\n",
    "\n",
    "splatcloud = o3d.io.read_point_cloud(splatcloud_path)\n",
    "splatcloud.transform(inv_hom)\n",
    "splatcloud.scale(inv_scale, center=(0, 0, 0))\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((0, 0, np.pi/2))\n",
    "splatcloud.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "gtmesh = o3d.io.read_triangle_mesh(gtmesh_path)\n",
    "gtcloud = gtmesh.sample_points_uniformly(number_of_points=len(splatcloud.points))\n",
    "\n",
    "splat_T = torch.tensor(np.array(splatcloud.points)).float().unsqueeze(0)\n",
    "gt_T = torch.tensor(np.array(gtcloud.points)).float().unsqueeze(0)\n",
    "\n",
    "a, _ = chamfer_distance(splat_T, gt_T)\n",
    "b, _ = chamfer_distance(gt_T, splat_T)\n",
    "chamfer_whole = (a + b) / 2\n",
    "chamfer_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_tf': Parameter containing:\n",
       " tensor([-2.5436e-04, -2.7187e-04,  2.9071e-04, -2.1155e-04,  1.2039e-04,\n",
       "          7.2967e-05], requires_grad=True),\n",
       " 'joint_axis': Parameter containing:\n",
       " tensor([-0.6293,  0.1697,  0.1178], requires_grad=True),\n",
       " 'joint_params': Parameter containing:\n",
       " tensor([[ 0.0000],\n",
       "         [-0.7632]], requires_grad=True)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "config_vector_path = '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/configuration_vector.pkl'\n",
    "with open(config_vector_path, 'rb') as f:\n",
    "    config_vector = pkl.load(f)\n",
    "\n",
    "joint = config_vector[0]['predicted_joint']\n",
    "joint.get_gt_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'src_part': 0,\n",
       "  'tgt_part': 1,\n",
       "  'predicted_prismatic': PrismaticJoint(),\n",
       "  'predicted_revolute': RevoluteJoint(),\n",
       "  'predicted_joint': PrismaticJoint()}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link_0'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from yourdfpy import URDF\n",
    "\n",
    "# robot = URDF.load(sapien_dir + 'mobility.urdf')\n",
    "# all_links = set(link.name for link in robot.robot.links)\n",
    "# parent_links = set(joint.parent for joint in robot.robot.joints)\n",
    "\n",
    "# # Leaf links are those that are not parent links\n",
    "# leaf_links = all_links - parent_links\n",
    "# leaf_links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

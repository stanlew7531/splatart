{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import json\n",
    "\n",
    "# Read .ply file\n",
    "transforms_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_0/dataparser_transforms.json\"\n",
    "splatcloud_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/exports/splat/splat.ply\"\n",
    "\n",
    "splatcloud = o3d.io.read_point_cloud(splatcloud_path)\n",
    "# Get and invert transforms\n",
    "transforms = json.load(open(transforms_path, 'r'))\n",
    "inv_scale = 1.0 / transforms['scale']\n",
    "\n",
    "linear = np.array(transforms['transform'])[0:3, 0:3]\n",
    "T = np.array(transforms['transform'])[0:3, 3]\n",
    "inv = np.linalg.inv(linear)\n",
    "\n",
    "inv_hom = np.eye(4)\n",
    "inv_hom[0:3, 0:3] = inv\n",
    "inv_hom[0:3, 3] = -inv @ T\n",
    "\n",
    "# apply transforms\n",
    "# splatcloud.transform(inv_hom)\n",
    "# splatcloud.scale(inv_scale, center=(0, 0, 0))\n",
    "\n",
    "# correct for convention difference\n",
    "# R = o3d.geometry.get_rotation_matrix_from_xyz((0, 0, np.pi/2))\n",
    "# splatcloud.rotate(R, center=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get canonical parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['original-3', 'original-2', 'original-5', 'original-31', 'original-32']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read .ply file\n",
    "paris_to_sapien = {\n",
    "    'blade': '103706',\n",
    "    'laptop': '10211',\n",
    "    'foldchair': '102255',\n",
    "    'oven': '101917',\n",
    "    'fridge': '10905',\n",
    "    'scissor': '11100',\n",
    "    'stapler': '103111',\n",
    "    'USB': '100109',\n",
    "    'washer': '103776',\n",
    "    'storage': '45135'\n",
    "}\n",
    "\n",
    "name = 'blade'\n",
    "sapien_dir = '/home/vishalchandra/Desktop/sapien_dataset/' + paris_to_sapien[name] + '/'\n",
    "description = json.load(open(sapien_dir + 'result.json'))[0]\n",
    "parts = description['children']\n",
    "\n",
    "parts_files = [part['objs'] for part in parts]\n",
    "parts_files[0][:5] #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TriangleMesh with 290 points and 248 triangles.,\n",
       " TriangleMesh with 38 points and 30 triangles.,\n",
       " TriangleMesh with 80 points and 80 triangles.,\n",
       " TriangleMesh with 96 points and 96 triangles.,\n",
       " TriangleMesh with 72 points and 70 triangles.]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canonical_part_objs = [\n",
    "    [o3d.io.read_triangle_mesh(sapien_dir + 'textured_objs/' + obj + '.obj') for obj in part]\n",
    "    for part in parts_files\n",
    "]\n",
    "canonical_part_objs[0][:5] #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all triangle meshes to a single mesh but keep them separate\n",
    "canonical_parts = []\n",
    "for part in canonical_part_objs:\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    for obj in part:\n",
    "        mesh += obj\n",
    "    canonical_parts.append(mesh)\n",
    "\n",
    "# correct for convention differences between sapien and reconstruction\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((np.pi/2, -np.pi/2, 0))\n",
    "for part in canonical_parts:\n",
    "    part.rotate(R, center=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Reconstructed Parts from Gauss Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Don't need to interact with pipelines\n",
    "# from splatart.managers.SplatManager import SplatManager, load_model\n",
    "# to be cmd line args\n",
    "# model_dirs = [\n",
    "#     '/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_0',\n",
    "#     '/home/vishalchandra/Desktop/nerfstudio_dev/outputs/exp_sapien_blade/semantic-splatfacto/config_1'\n",
    "# ]\n",
    "# num_classes = 4\n",
    "# ns_base_path = '/home/vishalchandra/Desktop/nerfstudio_dev/'\n",
    "\n",
    "# trainer_config, pipeline, ckpt_path = load_model(model_dirs[0], 'config.yml', ns_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "manager_paths = [\n",
    "    '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/splat_manager_0.pth',\n",
    "    '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/splat_manager_1.pth'\n",
    "]\n",
    "\n",
    "managers = [torch.load(manager_path) for manager_path in manager_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyElement, PlyData\n",
    "import numpy as np\n",
    "\n",
    "# adapted from https://github.com/nerfstudio-project/gsplat/issues/234#issuecomment-2197277211\n",
    "def part_to_ply(part, part_num):\n",
    "\n",
    "    xyz = part[\"means\"].detach().cpu().numpy()\n",
    "    normals = np.zeros_like(xyz)\n",
    "    f_dc = part[\"features_dc\"].detach().contiguous().cpu().numpy()\n",
    "    f_rest = part[\"features_rest\"].transpose(1, 2).flatten(start_dim=1).detach().contiguous().cpu().numpy()\n",
    "    opacities = part[\"opacities\"].detach().cpu().numpy()\n",
    "    scale = part[\"scales\"].detach().cpu().numpy()\n",
    "    rotation = part[\"quats\"].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    l = ['x', 'y', 'z', 'nx', 'ny', 'nz']\n",
    "    # All channels except the 3 DC\n",
    "    for i in range(part.features_dc.shape[1]):\n",
    "        l.append('f_dc_{}'.format(i))\n",
    "    for i in range(part.features_rest.shape[1]*part.features_rest.shape[2]):\n",
    "        l.append('f_rest_{}'.format(i))\n",
    "    l.append('opacity')\n",
    "    for i in range(part.scales.shape[1]):\n",
    "        l.append('scale_{}'.format(i))\n",
    "    for i in range(part.quats.shape[1]):\n",
    "        l.append('rot_{}'.format(i))\n",
    "\n",
    "    dtype_full = [(attribute, 'f4') for attribute in l]\n",
    "\n",
    "    elements = np.empty(xyz.shape[0], dtype=dtype_full)\n",
    "    attributes = np.concatenate((xyz, normals, f_dc, f_rest, opacities, scale, rotation), axis=1)\n",
    "    elements[:] = list(map(tuple, attributes))\n",
    "    el = PlyElement.describe(elements, 'vertex')\n",
    "    PlyData([el]).write('part{}.ply'.format(part_num))\n",
    "\n",
    "\n",
    "for i in range(2, managers[0].num_parts):\n",
    "    part = managers[0].parts_gauss_params[i]\n",
    "    part_to_ply(part, i-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare recon and canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_corresp = {\n",
    "    0: 1,\n",
    "    1: 0\n",
    "}\n",
    "\n",
    "recon_part_clouds = [\n",
    "    o3d.io.read_point_cloud('part{}.ply'.format(i)) for i in range(2)\n",
    "]\n",
    "\n",
    "# apply transforms\n",
    "for part_cloud in recon_part_clouds:\n",
    "    part_cloud.transform(inv_hom)\n",
    "    part_cloud.scale(inv_scale, center=(0, 0, 0))\n",
    "\n",
    "canonical_part_clouds = [\n",
    "    canonical_parts[canonical_corresp[i]].sample_points_uniformly(len(recon_part_clouds[i].points))\n",
    "    for i in range(2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=1.042831e-01, inlier_rmse=1.318809e-02, and correspondence_set size of 56\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99998869 -0.00336864 -0.00335696  0.00130347]\n",
      " [ 0.00356358  0.9982002   0.05986372 -0.00145096]\n",
      " [ 0.00314926 -0.059875    0.99820091 -0.00166862]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# register moving parts\n",
    "# here, we know it's part 1\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    recon_part_clouds[1], canonical_part_clouds[1], 0.02, np.eye(4),\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    ")\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0007), tensor(0.0356)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "part_chamfers = []\n",
    "movable = [1]\n",
    "for i in range(2):\n",
    "\n",
    "    recon_cloud = recon_part_clouds[i]\n",
    "    canonical_cloud = canonical_part_clouds[i]\n",
    "\n",
    "    if i in movable:\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            recon_part_clouds[1], canonical_part_clouds[1], 0.02, np.eye(4),\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000)\n",
    "        )\n",
    "        recon_cloud.transform(reg_p2p.transformation)\n",
    "        \n",
    "    recon_T = torch.tensor(np.array(recon_cloud.points)).float().unsqueeze(0)\n",
    "    canonical_T = torch.tensor(np.array(canonical_cloud.points)).float().unsqueeze(0)\n",
    "\n",
    "    a, _ = chamfer_distance(recon_T, canonical_T)\n",
    "    b, _ = chamfer_distance(canonical_T, recon_T)\n",
    "    part_chamfers.append((a + b)/2)\n",
    "\n",
    "part_chamfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0007)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splatcloud_path = \"/home/vishalchandra/Desktop/nerfstudio_dev/exports/splat/splat.ply\"\n",
    "gtmesh_path = \"/home/vishalchandra/Desktop/splatart_data/narf_sapien_data/v5/blade/0/blade_0.ply\"\n",
    "\n",
    "splatcloud = o3d.io.read_point_cloud(splatcloud_path)\n",
    "splatcloud.transform(inv_hom)\n",
    "splatcloud.scale(inv_scale, center=(0, 0, 0))\n",
    "R = o3d.geometry.get_rotation_matrix_from_xyz((0, 0, np.pi/2))\n",
    "splatcloud.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "gtmesh = o3d.io.read_triangle_mesh(gtmesh_path)\n",
    "gtcloud = gtmesh.sample_points_uniformly(number_of_points=len(splatcloud.points))\n",
    "\n",
    "splat_T = torch.tensor(np.array(splatcloud.points)).float().unsqueeze(0)\n",
    "gt_T = torch.tensor(np.array(gtcloud.points)).float().unsqueeze(0)\n",
    "\n",
    "a, _ = chamfer_distance(splat_T, gt_T)\n",
    "b, _ = chamfer_distance(gt_T, splat_T)\n",
    "chamfer_whole = (a + b) / 2\n",
    "chamfer_whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get joint for joint metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_tf': Parameter containing:\n",
       " tensor([-2.5436e-04, -2.7187e-04,  2.9071e-04, -2.1155e-04,  1.2039e-04,\n",
       "          7.2967e-05], requires_grad=True),\n",
       " 'joint_axis': Parameter containing:\n",
       " tensor([-0.6293,  0.1697,  0.1178], requires_grad=True),\n",
       " 'joint_params': Parameter containing:\n",
       " tensor([[ 0.0000],\n",
       "         [-0.7632]], requires_grad=True)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "config_vector_path = '/home/vishalchandra/Desktop/splatart/results/sapien_exp/blade/configuration_vector.pkl'\n",
    "with open(config_vector_path, 'rb') as f:\n",
    "    config_vector = pkl.load(f)\n",
    "\n",
    "joint = config_vector[0]['predicted_joint']\n",
    "joint_params = joint.get_gt_parameters()\n",
    "joint_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get pre transform matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00, -2.9071e-04, -2.7187e-04, -2.1155e-04],\n",
       "        [ 2.9078e-04,  1.0000e+00,  2.5436e-04,  1.2039e-04],\n",
       "        [ 2.7180e-04, -2.5444e-04,  1.0000e+00,  7.2967e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch3d.transforms as p3dt\n",
    "\n",
    "pre_tf = joint_params['pre_tf'].detach()\n",
    "initial_tf_rot = p3dt.euler_angles_to_matrix(pre_tf[:3], \"XYZ\") # (4, 4)\n",
    "initial_tf = torch.eye(4)\n",
    "initial_tf[:3, :3] = initial_tf_rot[:3, :3]\n",
    "initial_tf[:3, 3] = pre_tf[3:6]\n",
    "initial_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6296],\n",
       "        [ 0.1697],\n",
       "        [ 0.1177],\n",
       "        [ 1.0000]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_axis_hom = torch.ones(4, 1)\n",
    "joint_axis_hom[:3, 0] = joint_params['joint_axis'].detach()\n",
    "pred_axis = initial_tf @ joint_axis_hom\n",
    "pred_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9570,  0.2568,  0.1351])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## so far, there have been 3 spaces (2 transforms) that we have worked with\n",
    "## (1) sapien space where we got gt part meshes, (2) splat space where we got splatcloud, (3) ground truth space where we got gtcloud\n",
    "## (1) --> (2) was XYZ = (pi/2, -pi/2, 0), (2) --> (3) was inv_hom, inv_scale, XYZ = (0, 0, pi/2)\n",
    "## axis is in (2) space, gt axis is in (3) space\n",
    "\n",
    "\n",
    "# inv_hom, inv_scale doesn't matter here\n",
    "pred_axis = torch.tensor(inv_hom, dtype=torch.float32) @ pred_axis\n",
    "pred_axis = (pred_axis / pred_axis[3, 0])[:3, 0]\n",
    "pred_axis = pred_axis / np.linalg.norm(pred_axis)\n",
    "\n",
    "#rotating the axis to match the gt axis\n",
    "# joint_axis = p3dt.euler_angles_to_matrix(torch.tensor([0, 0, np.pi/2]), \"XYZ\") @ joint_axis\n",
    "pred_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.1155e-04,  1.2039e-04,  7.2967e-05])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_axis_o = pre_tf[3:].detach()\n",
    "pred_axis_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, get gt axis and apply gt base link transform to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000e+00,  3.8286e-16, -3.8286e-16], dtype=torch.float64)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yourdfpy import URDF\n",
    "\n",
    "robot = URDF.load(sapien_dir + 'mobility.urdf')\n",
    "\n",
    "base_joint, joint = None, None\n",
    "for j in robot.joint_map.values():\n",
    "    if j.type == 'fixed':\n",
    "        base_joint = j\n",
    "    else:\n",
    "        joint = j\n",
    "\n",
    "gt_pre_tf = base_joint.origin\n",
    "gt_axis = joint.axis\n",
    "\n",
    "gt_axis = torch.tensor(gt_pre_tf)[:3, :3] @ torch.tensor(gt_axis)\n",
    "gt_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_axis_o = torch.tensor(gt_pre_tf[0:3, 3] + joint.origin[0:3, 3])\n",
    "gt_axis_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis comparison: angle arror and pos error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(16.8705, dtype=torch.float64), tensor(8.5271e-06, dtype=torch.float64))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from https://github.com/NVlabs/DigitalTwinArt/blob/1a48b402e4bf4bb7731296e8e230f0db3d86fe4f/utils/articulation_utils.py#L148\n",
    "# angular difference between two vectors\n",
    "pred_axis = pred_axis.double()\n",
    "pred_axis_o = pred_axis_o.double()\n",
    "\n",
    "cos_theta = torch.dot(pred_axis, gt_axis) / (torch.norm(pred_axis) * torch.norm(gt_axis))\n",
    "ang_err = torch.rad2deg(torch.acos(torch.abs(cos_theta)))\n",
    "# positonal difference between two axis lines\n",
    "w = gt_axis_o - pred_axis_o\n",
    "cross = torch.cross(pred_axis, gt_axis)\n",
    "if (cross == torch.zeros(3)).sum().item() == 3:\n",
    "    pos_err = torch.tensor(0)\n",
    "else:\n",
    "    pos_err = torch.abs(torch.sum(w * cross)) / torch.norm(cross)\n",
    "\n",
    "ang_err, pos_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part motion comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19999998807907104"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from splatart.networks.NarfJoint import PrismaticJoint\n",
    "\n",
    "pred_motion = joint_params['joint_params'][1, 0].item()\n",
    "\n",
    "training_root = \"/home/vishalchandra/Desktop/splatart_data/narf_sapien_data/v5/blade\"\n",
    "gt_param_0 = list(json.load(open(training_root + '/0/transforms.json'))['configurations'].values())[0]\n",
    "gt_param_1 = list(json.load(open(training_root + '/1/transforms.json'))['configurations'].values())[0]\n",
    "gt_motion = [final - init for init,final in zip(gt_param_0, gt_param_1) if init != final][0]\n",
    "gt_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8295, dtype=torch.float64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.normalize(pred_axis, p=2, dim=0)\n",
    "F.normalize(gt_axis, p=2, dim=0)\n",
    "\n",
    "if isinstance(config_vector[0]['predicted_joint'], PrismaticJoint):\n",
    "    err = torch.sqrt((pred_motion * pred_axis - gt_motion * gt_axis)**2).sum()\n",
    "else:\n",
    "    pred_R = p3dt.axis_angle_to_matrix(pred_motion * pred_axis)\n",
    "    gt_R = p3dt.axis_angle_to_matrix(gt_motion * gt_axis)\n",
    "\n",
    "    pred_R, gt_R = pred_R.cpu(), gt_R.cpu()\n",
    "    R_diff = torch.matmul(pred_R, gt_R.T)\n",
    "    cos_angle = torch.clip((torch.trace(R_diff) - 1.0) * 0.5, min=-1., max=1.)\n",
    "    angle = torch.rad2deg(torch.arccos(cos_angle))\n",
    "\n",
    "    err = angle\n",
    "\n",
    "err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

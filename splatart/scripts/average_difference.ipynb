{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splatart.networks.PoseEstimator import PoseEstimator\n",
    "from splatart.managers.SplatManager import SplatManagerSingle\n",
    "import json\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_path = '../arm_accuracy_pths/seg_learned_manager_0.pth'\n",
    "pose_estimator_path = '../arm_accuracy_pths/pose_estimator.pth'\n",
    "gauss_param_path = '../arm_accuracy_pths/part_gauss_params.pth'\n",
    "transforms_path = '../arm_accuracy_pths/transforms.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splatManager = torch.load(manager_path)\n",
    "poseEstimator = torch.load(pose_estimator_path)\n",
    "gaussParams = torch.load(gauss_param_path)\n",
    "transforms = json.load(open(transforms_path, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataParser info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3335080532301977,\n",
       " tensor([[ 9.9778e-01, -8.8128e-04, -6.6559e-02,  3.4200e-09],\n",
       "         [-8.8128e-04,  9.9965e-01, -2.6447e-02,  1.1238e-08],\n",
       "         [ 6.6559e-02,  2.6447e-02,  9.9743e-01,  1.5395e-10],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_scale, dp_tf_matrix = splatManager.dataparser_scale, splatManager.dataparser_tf_matrix.cpu()\n",
    "dp_scale, dp_tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_means = [gaussParams[0][i]['means'].detach().cpu() for i in range(poseEstimator.num_parts)]\n",
    "len(gauss_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoseEstimator info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poseEstimator.num_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_estim = poseEstimator.part_means[0, :, :].detach().cpu()\n",
    "rot_estim = poseEstimator.part_eulers[0, :, :].detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GT Transforms info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_transforms = transforms['gt_part_world_poses']['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD Metric per Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "add_values = {}\n",
    "\n",
    "for i in range(poseEstimator.num_parts):\n",
    "    part_name = list(gt_transforms.keys())[i]\n",
    "\n",
    "    gt_transform = np.array(gt_transforms[part_name])\n",
    "    gt_transform = torch.from_numpy(gt_transform).float()\n",
    "\n",
    "    # convert translation and euler angles to 4x4 rotation matrix\n",
    "    pred_transform = torch.eye(4)\n",
    "    pred_transform[:3, :3] = torch.from_numpy(R.from_euler('xyz', rot_estim[i]).as_matrix())\n",
    "    pred_transform[3, :3] = trans_estim[i]\n",
    "    pred_transform = pred_transform.float()\n",
    "\n",
    "    # invert dataparser transform\n",
    "    pred_transform = torch.linalg.inv(dp_tf_matrix) @ pred_transform\n",
    "    pred_transform = pred_transform / dp_scale\n",
    "\n",
    "    # apply to gaussian means\n",
    "    pred_gauss_mean = gauss_means[i]\n",
    "    pred_gauss_mean = torch.cat((pred_gauss_mean, torch.ones(pred_gauss_mean.shape[0], 1)), dim=1)\n",
    "    pred_gauss_mean = pred_transform @ pred_gauss_mean.T\n",
    "    pred_gauss_mean = pred_gauss_mean.T[:, :3]\n",
    "\n",
    "    gt_gauss_mean = torch.from_numpy(np.array(gt_transform[:3, 3])).float()\n",
    "    gt_gauss_mean = gt_gauss_mean.unsqueeze(0)\n",
    "    gt_gauss_mean = torch.cat((gt_gauss_mean, torch.ones(gt_gauss_mean.shape[0], 1)), dim=1)\n",
    "    gt_gauss_mean = torch.linalg.inv(gt_transform) @ gt_gauss_mean.T\n",
    "    gt_gauss_mean = gt_gauss_mean.T[:, :3]\n",
    "\n",
    "    # compute ADD metric\n",
    "    add = torch.norm(pred_gauss_mean - gt_gauss_mean, dim=1).mean()\n",
    "    add_values[part_name] = add.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'panda_link0': nan,\n",
       " 'panda_link1': 0.09673026949167252,\n",
       " 'panda_link2': 0.27024930715560913,\n",
       " 'panda_link3': 0.3905125558376312,\n",
       " 'panda_link4': 0.5522987246513367,\n",
       " 'panda_link5': 0.6008105278015137,\n",
       " 'panda_link6': 0.41271713376045227,\n",
       " 'panda_link7': 0.44242098927497864,\n",
       " 'panda_link8': 0.46363022923469543,\n",
       " 'panda_hand': 0.44844189286231995,\n",
       " 'panda_leftfinger': 0.5124382376670837,\n",
       " 'panda_rightfinger': 0.4623609185218811}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADD_metric(splatManager:SplatManagerSingle, poseEstimator:PoseEstimator, gaussParams:list, transforms:dict, scene_id:int):\n",
    "    \"\"\"\n",
    "    Computes the ADD metric for a given prediction and ground truth.\n",
    "    \"\"\"\n",
    "\n",
    "    # dataparser and means\n",
    "    dp_scale, dp_tf_matrix = splatManager.dataparser_scale, splatManager.dataparser_tf_matrix.cpu()\n",
    "    gauss_means = [gaussParams[scene_id][i]['means'].detach().cpu() for i in range(poseEstimator.num_parts)]\n",
    "\n",
    "    # estimated transforms\n",
    "    trans_estim = poseEstimator.part_means[scene_id, :, :].detach().cpu()\n",
    "    rot_estim = poseEstimator.part_eulers[scene_id, :, :].detach().cpu()\n",
    "\n",
    "    # ground truth transforms\n",
    "    gt_transforms = transforms['gt_part_world_poses'][str(scene_id)]\n",
    "\n",
    "    add_values = {}\n",
    "    for i in range(poseEstimator.num_parts):\n",
    "        part_name = list(gt_transforms.keys())[i]\n",
    "\n",
    "        gt_transform = np.array(gt_transforms[part_name])\n",
    "        gt_transform = torch.from_numpy(gt_transform).float()\n",
    "\n",
    "        # convert translation and euler angles to 4x4 rotation matrix\n",
    "        pred_transform = torch.eye(4)\n",
    "        pred_transform[:3, :3] = torch.from_numpy(R.from_euler('xyz', rot_estim[i]).as_matrix())\n",
    "        pred_transform[3, :3] = trans_estim[i]\n",
    "        pred_transform = pred_transform.float()\n",
    "\n",
    "        # invert dataparser transform\n",
    "        pred_transform = torch.linalg.inv(dp_tf_matrix) @ pred_transform\n",
    "        pred_transform = pred_transform / dp_scale\n",
    "\n",
    "        # apply to gaussian means\n",
    "        pred_gauss_mean = gauss_means[i]\n",
    "        pred_gauss_mean = torch.cat((pred_gauss_mean, torch.ones(pred_gauss_mean.shape[0], 1)), dim=1)\n",
    "        pred_gauss_mean = pred_transform @ pred_gauss_mean.T\n",
    "        pred_gauss_mean = pred_gauss_mean.T[:, :3]\n",
    "\n",
    "        gt_gauss_mean = torch.from_numpy(np.array(gt_transform[:3, 3])).float()\n",
    "        gt_gauss_mean = gt_gauss_mean.unsqueeze(0)\n",
    "        gt_gauss_mean = torch.cat((gt_gauss_mean, torch.ones(gt_gauss_mean.shape[0], 1)), dim=1)\n",
    "        gt_gauss_mean = torch.linalg.inv(gt_transform) @ gt_gauss_mean.T\n",
    "        gt_gauss_mean = gt_gauss_mean.T[:, :3]\n",
    "\n",
    "        # compute ADD metric\n",
    "        add = torch.norm(pred_gauss_mean - gt_gauss_mean, dim=1).mean()\n",
    "        add_values[part_name] = add.item()\n",
    "\n",
    "    return add_values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'panda_link0': nan,\n",
       " 'panda_link1': 0.09673026949167252,\n",
       " 'panda_link2': 0.27024930715560913,\n",
       " 'panda_link3': 0.3905125558376312,\n",
       " 'panda_link4': 0.5522987246513367,\n",
       " 'panda_link5': 0.6008105278015137,\n",
       " 'panda_link6': 0.41271713376045227,\n",
       " 'panda_link7': 0.44242098927497864,\n",
       " 'panda_link8': 0.46363022923469543,\n",
       " 'panda_hand': 0.44844189286231995,\n",
       " 'panda_leftfinger': 0.5124382376670837,\n",
       " 'panda_rightfinger': 0.4623609185218811}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_values = ADD_metric(splatManager, poseEstimator, gaussParams, transforms, 0)\n",
    "add_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
